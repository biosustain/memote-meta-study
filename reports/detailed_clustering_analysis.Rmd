---
title: "Detailed Clustering Analysis"
output:
  bookdown::html_document2:
    toc: true
    toc_depth: 3
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Discriminant Factors


```{r}
library(fpc) # pamk
library(cluster) # pam
library(ape)
df=read.csv('../data/clustering_features.csv.gz')
id.vector=paste(df$collection,df$model,sep='_')
rownames(df)=id.vector
df.num=subset(df,select=-c(1:2))
```

```{r}
colsCollection=c("#A6A9AA","#000000","#3E7CBC","#A3D2E2","#7E8082","#EDA85F","#CD2028") #labels=c('agora','bigg','ebrahim','embl','path','seed','uminho')
```

```{r Feature importance functions}

#############################################
### plot.rf.var.importance.by.class.heatmap
#############################################
# Plot heatmap with variable importance independent by predicted class.
# Args:
#   model: random forest model already build
#   predVar: string of column ID with predictor/variables names values
#   classVar: string of class variable in 'df'
#   title: header of the plot
plot.rf.var.importance.by.class.heatmap <- function(model,predVar,classVar,title){
  imp.df=melt(importance(model)[,1:length(model$classes)])
  colnames(imp.df)=c(predVar,classVar,'testImportance')
  # a.-Order rows
  pred.order=names(sort(importance(model)[,'MeanDecreaseAccuracy'])) # My order according to global MeandDecreaseAccuracy
  imp.df[,predVar] <- factor(imp.df[,predVar], levels = pred.order)
  ggplot(data = imp.df, aes_string(x = classVar, y = predVar, fill= 'testImportance')) + geom_tile() + scale_fill_gradient2() +
    theme(axis.text.x = element_text(angle = 270, hjust = 1)) +
    ggtitle(title)
}

#############################################
### plot.rf.var.importance.by.class.dotplot
#############################################
# Plot dotplot with variable importance independent by predicted class.
# Args:
#   model: random forest model already build
#   predVar: string of column ID with predictor/variables names values
#   classVar: string of class variable in 'df'
#   title: header of the plot
plot.rf.var.importance.by.class.dotplot <- function(model,predVar,classVar,title){
  imp.df=melt(importance(model)[,1:length(model$classes)])
  colnames(imp.df)=c(predVar,classVar,'value')
  # a.-Order rows
  pred.order=names(sort(importance(model)[,'MeanDecreaseAccuracy'])) # My order according to global MeandDecreaseAccuracy
  imp.df[,predVar] <- factor(imp.df[,predVar], levels = pred.order)
  imp.df[,classVar] <- factor(imp.df[,classVar])
  # b.-Order class
  ggplot(imp.df, aes_string(x = 'value', y = predVar, group = predVar, colour = classVar)) +
    geom_segment(aes_string(yend=predVar), xend=0, colour="grey50") +
    geom_point( size = 1) +
    scale_color_manual(values=colsCollection) +
    theme_bw() +
    facet_grid(reformulate(classVar)) +
    theme(panel.grid.major.y = element_blank()) +
    theme(text = element_text(size=12)) +
    xlab(paste(predVar," importance (Mean Decrease in Accuracy in RandomForest)",sep='')) +
    theme(axis.text.x = element_text(angle = 270, hjust = 1)) +
    theme(legend.position="none")
}

####################################################
### plot.rf.var.importance.by.class.andMean.heatmap
###################################################
# Plot heatmap with variable importance mean over all classes
# Args:
#   model: random forest model already build
#   predVar: string of column ID with predictor/variables names values
#   classVar: string of class variable in 'df'
#   title: header of the plot
plot.rf.var.importance.by.class.andMean.heatmap <- function(model,predVar,classVar,title){
  imp.df=melt(importance(model)[,1:(length(model$classes)+1)])
  colnames(imp.df)=c(predVar,classVar,'testImportance')
  # a.-Order rows
  pred.order=names(sort(importance(model)[,'MeanDecreaseAccuracy'])) # My order according to global MeandDecreaseAccuracy
  imp.df[,predVar] <- factor(imp.df[,predVar], levels = pred.order)
  # Change names classes (MeanDecreasAccuracy --> Mean)
  class.names=levels(imp.df[,classVar])
  levels(imp.df[,classVar]) <- c(class.names[1:(length(class.names)-1)],"MEAN")
  imp.df[,classVar] <- factor(imp.df[,classVar])
  ggplot(data = imp.df, aes_string(x = classVar, y = predVar, fill= 'testImportance')) + geom_tile() + scale_fill_gradient2() +
    theme(axis.text.x = element_text(angle = 270, hjust = 1)) +
    ggtitle(title)
}


####################################################
### plot.rf.var.importance.by.class.andMean.dotplot
####################################################
# Plot dotplot with variable importance mean over all classes
# Args:
#   model: random forest model already build
#   predVar: string of column ID with predictor/variables names values
#   classVar: string of class variable in 'df'
#   colorVector: vector of colors
#   nBestFeatures: number of top relevant features to show in the plot.
#   classNames: vector with ad-hoc class names.
plot.rf.var.importance.by.class.andMean.dotplot <- function(model,predVar,classVar,colorVector=NULL,nBestFeatures=NULL,classNames=NULL){
  imp.df=melt(importance(model)[,1:(length(model$classes)+1)])
  colnames(imp.df)=c(predVar,classVar,'value')
  # a.-Order rows
  pred.order=names(sort(importance(model)[,'MeanDecreaseAccuracy'])) # My order according to global MeandDecreaseAccuracy
  imp.df[,predVar] <- factor(imp.df[,predVar], levels = pred.order)
  class.names=levels(imp.df[,classVar])
  if(!is.null(classNames)){
    levels(imp.df[,classVar]) <- c(classNames,'MEAN')
  }else{
    levels(imp.df[,classVar]) <- c(class.names[1:(length(class.names)-1)],'MEAN')
  }
  imp.df[,classVar] <- factor(imp.df[,classVar])
  # b.- Subset test to show
  if(!is.null(nBestFeatures)){
    imp.df=subset(imp.df,subset=(test %in% tail(pred.order,n=nBestFeatures)))
  }
  p <- ggplot(imp.df, aes_string(x = 'value', y = predVar, group = predVar, colour = classVar)) +
    geom_segment(aes_string(yend=predVar), xend=0, colour="grey50") +
    geom_point( size = 3) +
    theme_bw() +
    facet_grid(reformulate(classVar)) +
    theme(panel.grid.major.y = element_blank()) +
    theme(text = element_text(size=16)) +
    xlab(paste(predVar," importance (Mean Decrease in Accuracy)",sep='')) +
    theme(axis.text.x = element_text(angle = 270, hjust = 1)) +
    theme(legend.position="none")
  if(!is.null(colorVector)){
    p +  scale_color_manual(values=colorVector)
  }else{
    p
  }
}
```


```{r}
library(randomForest)
library(caret)
df.rf = subset(df, select = -c(2))
set.seed(123)
train_control <-
  trainControl(method = "cv",
               number = 10,
               savePredictions = "all")
rf_file <- "../data/rf_model_classCollection.Rdata"
if (!file.exists(rf_file)) {
  model <-
    train(
      form = collection ~ .,
      data = df.rf,
      trControl = train_control,
      method = "rf",
      ntree = 1000,
      importance = TRUE,
      localImp = TRUE,
      na.action = na.omit
    )
  save(model, file = "../data/rf_model_classCollection.Rdata")
} else {
  load(rf_file)
}
```

```{r fig.width=18, fig.height=9}
print(model$finalModel)
# Variable Importance
varImpPlot(model$finalModel,type=1)
# Confusion matrix
print(confusionMatrix(model$pred$pred,model$pred$obs))
model=model$finalModel
pred=model$pred
# Change names classes (MeanDecreasAccuracy --> Mean)
class.names=levels(model$classes)
levels(model$classes) <-c('AGORA','CarveMe','Path2Models','KBase','BiGG','Ebrahim et al.','OptFlux')
model$classes <- factor(model$classes)
```

```{r fig.width=10, fig.height=18}
library(reshape2)
plot.rf.var.importance.by.class.andMean.dotplot(model,'test','collection',colorVec=c(colsCollection,'#60d660'))
plot.rf.var.importance.by.class.andMean.heatmap(model,'test','collection','Feature importance (Mean Decreasy in Accuracy in Random Forest)')
```

```{r fig.width=10, fig.height=5}
plot.rf.var.importance.by.class.andMean.dotplot(model,'test','collection',colorVec=c(colsCollection,'#60d660'),nBestFeatures=15,classNames=c('AGORA','CarveMe','Path2Models','KBase','BiGG','Ebrahim et al.','OptFlux'))
```

## Clustering
```{r pamk, eval=FALSE}
fitPamBest <- pamk(df.num,krange=2:25)
save(fitPamBest,file='../data/fitPamBest_k2-25.Rdata')
write.table(as.matrix(fitPamBest$pamobject$clustering),paste("../data/pam_clusters_k",fitPamBest$nc,".txt",sep=""),quote=FALSE,sep='\t',col.names=NA,row.names=TRUE)
 #[1] 0.0000000 0.6994101 0.5969360 0.6976904 0.5068908 0.4770732 0.4372348
 #[8] 0.4513308 0.4319778 0.4467728 0.4305388 0.3842136 0.3688111 0.3674104
#[15] 0.3331504 0.3097679 0.3130108 0.3412444 0.3377852 0.3110066 0.3153869
#[22] 0.3001647 0.2838108 0.2866504 0.2949700
```

```{r PAM}
fit <- pam(df.num,2)
print(summary(silhouette(fit)))
fit <- pam(df.num,4)
print(summary(silhouette(fit)))
```

```{r HCLUST}
distMat <-dist(df.num)
fitH <- hclust(distMat)
SIbest=0
kbest=0
for(k in 2:25){
  si=summary(silhouette(cutree(fitH,k=k),distMat))$avg.width
  if(si>SIbest){
    SIbest=si
    kbest=k
  }
  print(paste(k,si,sep=':'))
}
```

```{r}
si<-silhouette(cutree(fitH,k=kbest),distMat)
summary(si)
fitH.labelModels=fitH
fitH$labels=gsub('_.*','',fitH$labels)
```


```{r}
library(RColorBrewer)
my.palette <- brewer.pal(kbest,"Paired")
cols <- colorRampPalette(my.palette)(kbest)
clusK=cutree(fitH,kbest)
plot(as.phylo(fitH), type = "fan", cex = 0.6, label.offset = 0.3, no.margin=TRUE, tip.color = cols[clusK])
```

```{r}
plot(as.phylo(fitH), type='unrooted', cex=0.5, label.offset=0.5, no.margin=TRUE, tip.color = cols[clusK])
```

```{r}
groups <- as.factor(cutree(fitH.labelModels, k = kbest))
write.table(
  as.matrix(groups),
  paste("../data/hclust_clusters_k", kbest, ".txt", sep = ""),
  quote = FALSE,
  sep = '\t',
  col.names = NA,
  row.names = TRUE
)
```


```{r}
library(RColorBrewer)
library(dendextend)

colsCluster=colorspace::rainbow_hcl(kbest, c = 70, l  = 50)

clusK=cutree(fitH,kbest,order_clusters_as_data = FALSE)

# define dendrogram
fitH.dend=as.dendrogram(fitH)
collec=labels(fitH.dend)

# Specify different point types and colors for each leave
dend <- fitH.dend %>% 
  set("leaves_pch", 19) %>%  # node point type
  set("leaves_cex", 0.4) %>%  # node point size
  #set("leaves_col", colsCollection[as.factor(fitH$labels)]) %>% #node point color
  set("labels", "") %>%
  set("branches_k_color", colsCluster, k = 10)
plot(dend)

# Add the colored bar
# Create a vector giving a color for each model collection
# Inspired by: https://cran.r-project.org/web/packages/dendextend/vignettes/FAQ.html
collect_type <- rep("Other", length(rownames(df.num)))
is_x <- grepl("agora", rownames(df.num))
collect_type[is_x] <- "agora"
is_x <- grepl("bigg", rownames(df.num))
collect_type[is_x] <- "bigg"
is_x <- grepl("ebrahim", rownames(df.num))
collect_type[is_x] <- "ebrahim"
is_x <- grepl("embl", rownames(df.num))
collect_type[is_x] <- "embl"
is_x <- grepl("path", rownames(df.num))
collect_type[is_x] <- "path"
is_x <- grepl("seed", rownames(df.num))
collect_type[is_x] <- "seed"
is_x <- grepl("uminho", rownames(df.num))
collect_type[is_x] <- "uminho"
collect_type <- factor(collect_type)
n_collect_types <- length(unique(collect_type))
col_collect_type <- colsCollection[collect_type]

colored_bars(col_collect_type, dend, rowLabels = "Collection")
```

```{r}
library(ggplot2)
ggd1 <- as.ggdend(dend)
# Create a radial plot and remove labels
ggplot(ggd1, labels = FALSE) +
  scale_y_reverse(expand = c(0.2, 0)) +
  coord_polar(theta = "x")
```




#### Discriminant factor of clusters

```{r}
df.rf = df.num
df.rf$cluster = as.factor(cutree(fitH, kbest))
set.seed(123)
rf_file = "../data/rf_model_classCluster.Rdata"
if (!file.exists(rf_file)) {
  model.cl <-
    train(
      form = cluster ~ .,
      data = df.rf,
      trControl = train_control,
      method = "rf",
      ntree = 1000,
      importance = TRUE,
      localImp = TRUE,
      na.action = na.omit,
      do.trace = 10
    )
  save(model.cl, file = rf_file)
} else {
  load(rf_file)
}
```

```{r fig.width=18, fig.height=9}
print(model.cl$finalModel)
# Variable Importance
varImpPlot(model.cl$finalModel,type=1)
# Confusion matrix
print(confusionMatrix(model.cl$pred$pred,model.cl$pred$obs))

model=model.cl$finalModel
pred=model.cl$pred
```


```{r fig.width=10, fig.height=18}
library(reshape2)
colVector=c(
  "#DB9D85",
"#E2979B",
"#E494B2",
"#DF94C6",
"#D297D5",
"#BD9EDF",
"#A2A7E2",
"#80B0DE",
"#5CB7D3",
"#3EBCC3",
"#3ABEAF",
"#52BE99",
"#70BB84",
"#8DB771",
"#A7B166",
"#BCAB66",
"#CEA472",
"#DB9D85")
# agora, bigg, bigg, bigg, ebrahim+path+uminho, ~embl, embl+path, path, seed, seed
plot.rf.var.importance.by.class.andMean.dotplot(model,'test','cluster',colVector)
plot.rf.var.importance.by.class.andMean.heatmap(model,'test','cluster','Feature importance (Mean Decreasy in Accuracy in Random Forest)')
```
